{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5-4_mlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deep-of-Machine/AI_Academy/blob/main/Deep_or_wide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74P_GzYNYRrQ"
      },
      "source": [
        "## GPU로 학습\n",
        "런타임 - 런타임 유형 변경 - GPU    \n",
        "이후 신경망을 학습할 때는 전부 런타임 유형을 GPU를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WjzwbAprbmg"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YMzCdom2jSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88775f6-44d9-4e03-b584-5bb32cde1d97"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8hJetV12r8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb12e829-5071-48a3-87b4-381ea6d16449"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "print(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rYhXYSFr7zp"
      },
      "source": [
        "transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5), (0.5))] )\n",
        "train_dataset = datasets.MNIST(root = './data', train = True, download = True, transform = transform)\n",
        "test_dataset = datasets.MNIST(root = './data', train = False, download = True, transform = transform)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF_lF3lHCBOe",
        "outputId": "78d31067-57b0-4316-8f65-685374dbcb31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=0.5, std=0.5)\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmeXDr1htX3I"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ImfZZjpCMoa"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I73l3ldkuoq_"
      },
      "source": [
        "class Deep_net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Deep_net, self).__init__()\n",
        "        self.layer1 = nn.Linear(784, 200)\n",
        "        self.layer2 = nn.Linear(200, 200)\n",
        "        self.layer5 = nn.Linear(200, 200)\n",
        "        self.layer6 = nn.Linear(200, 100)\n",
        "        self.layer9 = nn.Linear(100, 100)\n",
        "        self.layer10 = nn.Linear(100, 10)\n",
        "       \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.layer5(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.layer6(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.layer9(x)\n",
        "        x = F.relu(x)\n",
        "        out = self.layer10(x)\n",
        "        return out\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfA2rRnyCUNS"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVCAME72ZGMV"
      },
      "source": [
        ".to(device)를 사용해서 모델, 손실 함수, 데이터를 GPU에 할당"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yes9ed0exTvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1d648e-5c7a-4c56-ba2e-d411e1da76fc"
      },
      "source": [
        "model = Deep_net().to(device)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep_net(\n",
            "  (layer1): Linear(in_features=784, out_features=200, bias=True)\n",
            "  (layer2): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (layer5): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (layer6): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (layer9): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (layer10): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRGRVFInx1Rm"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0i5L1J_zNpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc7f80fb-76e1-467c-ed2b-37a576387864"
      },
      "source": [
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = loss_func(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    print('Epoch : {}, Loss : {}, time : {}'.format(epoch + 1, running_loss/len(train_loader), end_time - start_time))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1, Loss : 0.6319234291595945, time : 15.11596941947937\n",
            "Epoch : 2, Loss : 0.4105009633833284, time : 15.066384315490723\n",
            "Epoch : 3, Loss : 0.37137569620538113, time : 14.862892866134644\n",
            "Epoch : 4, Loss : 0.3530712251120539, time : 14.874088525772095\n",
            "Epoch : 5, Loss : 0.35126022899201687, time : 14.898571252822876\n",
            "Epoch : 6, Loss : 0.32834353202632244, time : 15.020339965820312\n",
            "Epoch : 7, Loss : 0.33492428227178833, time : 15.000990152359009\n",
            "Epoch : 8, Loss : 0.35445038131527556, time : 14.805065155029297\n",
            "Epoch : 9, Loss : 0.3473804171548596, time : 14.935123920440674\n",
            "Epoch : 10, Loss : 0.34905021613848997, time : 14.883912324905396\n",
            "Epoch : 11, Loss : 0.34872392777091404, time : 15.095586776733398\n",
            "Epoch : 12, Loss : 0.37169171903909903, time : 14.836329936981201\n",
            "Epoch : 13, Loss : 0.36016530942703995, time : 14.78528118133545\n",
            "Epoch : 14, Loss : 0.602942379124002, time : 14.671258926391602\n",
            "Epoch : 15, Loss : 0.9938453582049941, time : 14.787569999694824\n",
            "Epoch : 16, Loss : 0.5921468161888468, time : 14.718860387802124\n",
            "Epoch : 17, Loss : 0.47678044429624766, time : 14.802855730056763\n",
            "Epoch : 18, Loss : 0.5192437634380387, time : 14.759313344955444\n",
            "Epoch : 19, Loss : 0.5484618470946482, time : 14.868789434432983\n",
            "Epoch : 20, Loss : 0.5600684717742365, time : 14.824661493301392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6z5laBx3KyY",
        "outputId": "a34c5258-f75c-45c9-e922-5c399a718794"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        predicted = torch.argmax(outputs, dim = 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()  # 아래에 추가 설명\n",
        "\n",
        "    print(total)\n",
        "    print(100*correct / total)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "88.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVMIYO73D4ND"
      },
      "source": [
        "class WIde_net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WIde_net, self).__init__()\n",
        "        self.layer1 = nn.Linear(784, 3000)\n",
        "        self.layer3 = nn.Linear(3000, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = F.relu(x)\n",
        "        out = self.layer3(x)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEUkfcTcD76_",
        "outputId": "d4fd0a6a-9e82-487a-fcab-13bbc8078dd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = WIde_net().to(device)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WIde_net(\n",
            "  (layer1): Linear(in_features=784, out_features=3000, bias=True)\n",
            "  (layer3): Linear(in_features=3000, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjalfgWkD-EL"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRpHfW-sD_ab",
        "outputId": "053fc374-1194-4237-efe1-ff9aa844a03f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = loss_func(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    print('Epoch : {}, Loss : {}, time : {}'.format(epoch + 1, running_loss/len(train_loader), end_time - start_time))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1, Loss : 0.6603460444379717, time : 15.174087047576904\n",
            "Epoch : 2, Loss : 0.26054990094607827, time : 15.232318878173828\n",
            "Epoch : 3, Loss : 0.24336057305554432, time : 15.22301459312439\n",
            "Epoch : 4, Loss : 0.23815322038072195, time : 15.159773588180542\n",
            "Epoch : 5, Loss : 0.22388558222382055, time : 15.26331877708435\n",
            "Epoch : 6, Loss : 0.219382869030065, time : 15.350952625274658\n",
            "Epoch : 7, Loss : 0.21693759791052608, time : 15.368610620498657\n",
            "Epoch : 8, Loss : 0.21212219063446783, time : 15.395427227020264\n",
            "Epoch : 9, Loss : 0.21347045892877364, time : 15.380370616912842\n",
            "Epoch : 10, Loss : 0.2152462761614845, time : 15.214811086654663\n",
            "Epoch : 11, Loss : 0.2084739117849388, time : 15.238700151443481\n",
            "Epoch : 12, Loss : 0.2077753596466535, time : 15.246835470199585\n",
            "Epoch : 13, Loss : 0.20622095010920502, time : 15.195438623428345\n",
            "Epoch : 14, Loss : 0.19324525080319407, time : 15.285901069641113\n",
            "Epoch : 15, Loss : 0.20177922773409263, time : 15.271769285202026\n",
            "Epoch : 16, Loss : 0.20259179037485295, time : 15.339189052581787\n",
            "Epoch : 17, Loss : 0.20267580756952347, time : 15.285115242004395\n",
            "Epoch : 18, Loss : 0.19963469447494586, time : 15.16617751121521\n",
            "Epoch : 19, Loss : 0.19124173711755002, time : 15.232503414154053\n",
            "Epoch : 20, Loss : 0.1894991077494615, time : 15.25371527671814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zPYAVMOEL_b",
        "outputId": "810d4a17-ef03-4213-81e2-a08432ab898c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        predicted = torch.argmax(outputs, dim = 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()  # 아래에 추가 설명\n",
        "\n",
        "    print(total)\n",
        "    print(100*correct / total)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "93.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL7ycrHbpKGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c138d5a9-271f-407a-ad1b-90324901265c"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/day_5/Mnist_models.pth'\n",
        "print(PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/day_5/Mnist_models.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR-GdInK49lO"
      },
      "source": [
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmAVn6vMkDFP"
      },
      "source": [
        "model2를 새로 생성하고, model과 비교\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnSeJcR5A-_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed0eca4f-8a32-40a7-e102-a02d371f484b"
      },
      "source": [
        "model2 = MyNet()\n",
        "print(list(model.parameters())[1][:10])  # 위에서 학습한 model의 파라미터 일부\n",
        "print(list(model2.parameters())[1][:10]) # 새로 생성한 model2의 파라미터 일부"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0391,  0.0099,  0.0136,  0.0273, -0.0233,  0.0291,  0.0323, -0.0026,\n",
            "        -0.0011, -0.0178], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-0.0308, -0.0029, -0.0232,  0.0174, -0.0251,  0.0156,  0.0244,  0.0175,\n",
            "        -0.0282, -0.0191], grad_fn=<SliceBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1v8P9G55iM5"
      },
      "source": [
        "model2 = model2.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjcFVoce5dZh",
        "outputId": "fa23cd31-2c50-409e-bc58-acb60bb5a6db"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model2(inputs)\n",
        "        predicted = torch.argmax(outputs, dim = 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()  # 아래에 추가 설명\n",
        "\n",
        "    print(total)\n",
        "    print(100*correct / total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "7.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4yE5LQqpOvm"
      },
      "source": [
        "PATH에 저장된 가중치를 model2에 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2weomMvkn1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3273d3b-2294-4c1a-f5e0-9d51e383f83f"
      },
      "source": [
        "model2.load_state_dict(torch.load(PATH))\n",
        "print(list(model2.parameters())[1][:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0391,  0.0099,  0.0136,  0.0273, -0.0233,  0.0291,  0.0323, -0.0026,\n",
            "        -0.0011, -0.0178], device='cuda:0', grad_fn=<SliceBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL_RXfp658et",
        "outputId": "94f7f93c-c354-4e16-fd52-66ec52108162"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model2(inputs)\n",
        "        predicted = torch.argmax(outputs, dim = 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()  # 아래에 추가 설명\n",
        "\n",
        "    print(total)\n",
        "    print(100*correct / total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "91.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqs-_2pynke1"
      },
      "source": [
        "## 학습 가능한 파라미터 수 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1UQk0gHBLqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9489dc60-319e-4dbd-c996-351bc7b5fc42"
      },
      "source": [
        "model.parameters()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7fa6bf24fe50>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VgdLFiN7jQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b399bdb-c6c0-4ec5-a854-48ec71b12e2d"
      },
      "source": [
        "for i in model.parameters():\n",
        "    print(i)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0203,  0.0161,  0.0051,  ...,  0.0233,  0.0130,  0.0025],\n",
            "        [-0.0202,  0.0307,  0.0271,  ..., -0.0331, -0.0319,  0.0152],\n",
            "        [ 0.0015, -0.0115, -0.0267,  ...,  0.0234,  0.0164, -0.0153],\n",
            "        ...,\n",
            "        [ 0.0218, -0.0197, -0.0231,  ...,  0.0265,  0.0114, -0.0140],\n",
            "        [-0.0271, -0.0251,  0.0068,  ..., -0.0216,  0.0216,  0.0022],\n",
            "        [ 0.0327,  0.0228,  0.0061,  ...,  0.0132, -0.0330, -0.0232]],\n",
            "       device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sddch_0At2Zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559829e3-17fc-4704-b2c7-0fadc2f5b82e"
      },
      "source": [
        "print(i.requires_grad == True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K3Jmlxn8IVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2ac439-5a60-49e1-efac-475922cd58fa"
      },
      "source": [
        "print(i.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAdLf0letDVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85e599d-3551-4151-b965-2d2969ad6a67"
      },
      "source": [
        "print(i.shape[0] * i.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEWmVoBptDQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1f15c9-9a27-4a50-e59a-32a4a532cd03"
      },
      "source": [
        "print(i.numel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzHllrTK72V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd052a3-9a38-4e7b-812e-9c52943a278a"
      },
      "source": [
        "n = 0\n",
        "for i in model.parameters():\n",
        "    if i.requires_grad == True:\n",
        "        n += i.numel()\n",
        "\n",
        "print(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC4cybWfP2-g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUru6hlbbehA"
      },
      "source": [
        "직접 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktlhVK5zbMp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5442ec4-d7e0-41a6-c213-c967715097ad"
      },
      "source": [
        "128*784 + 128 + 32*128 + 32 + 10*32 + 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104938"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IungaOHznuA4"
      },
      "source": [
        "## 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HcDco25BOIa"
      },
      "source": [
        "for mini_batch in test_loader:\n",
        "    first_batch = mini_batch\n",
        "    break\n",
        "\n",
        "inputs = first_batch[0]\n",
        "labels = first_batch[1]\n",
        "outputs = model(inputs.view(inputs.shape[0], -1).to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBvTVIO182HW"
      },
      "source": [
        "sample_number = 0\n",
        "plt.imshow(inputs[sample_number].squeeze().numpy(), cmap = 'gray')\n",
        "plt.show()\n",
        "print('예측 : {}'.format(torch.argmax(outputs[sample_number]).item()))\n",
        "print('라벨 : {}'.format(labels[sample_number].item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkat4QVmBk_Y"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        predicted = torch.argmax(outputs, dim = 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(total)\n",
        "    print(100*correct / total)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}